2025-02-20 08:26:10.715527: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-20 08:26:10.733979: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1740057970.753267 1519795 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1740057970.758617 1519795 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-20 08:26:10.778777: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0220 08:26:25.440506 22739701924864 main.py:401] Seed: 0
I0220 08:26:25.458248 22739701924864 utils.py:25] Experiment directory: /share/csc591s25/sgundew/GenAI-for-Systems-Gym/homework-1/models/LSTM/experiments/LSTM_T1_default
I0220 08:26:25.483073 22739701924864 main.py:436] Model config: {
    "address_embedder": {
        "embed_dim": 64,
        "max_vocab_size": 5000,
        "type": "dynamic-vocab"
    },
    "cache_line_embedder": "address_embedder",
    "cache_pc_embedder": "none",
    "loss": [
        "ndcg",
        "reuse_dist"
    ],
    "lr": 0.001,
    "lstm_hidden_size": 128,
    "max_attention_history": 30,
    "pc_embedder": {
        "embed_dim": 64,
        "max_vocab_size": 5000,
        "type": "dynamic-vocab"
    },
    "positional_embedder": {
        "embed_dim": 128,
        "type": "positional"
    },
    "sequence_length": 80
}
I0220 08:26:25.489092 22739701924864 main.py:441] Cache config: {
    "associativity": 16,
    "cache_line_size": 64,
    "capacity": 2097152
}
I0220 08:26:25.493818 22739701924864 main.py:448] DAgger config: {
    "final": 1.0,
    "initial": 0.0,
    "num_steps": 200000,
    "type": "linear",
    "update_freq": 10000
}
I0220 08:26:25.503071 22739701924864 main.py:459] Device: cuda
W0220 08:26:25.787229 22739701924864 model.py:392] Expects that all calls to loss are labeled with Belady's
W0220 08:26:25.787403 22739701924864 model.py:405] Expects that all calls to loss are labeled with Belady's
Initializing MemoryTrace:   0%|          | 0/10000000 [00:00<?, ?it/s]Initializing MemoryTrace:   2%|▏         | 166559/10000000 [00:00<00:05, 1665456.58it/s]Initializing MemoryTrace:   5%|▍         | 459298/10000000 [00:00<00:03, 2407716.83it/s]Initializing MemoryTrace:   8%|▊         | 766654/10000000 [00:00<00:03, 2711733.79it/s]Initializing MemoryTrace:  11%|█         | 1084921/10000000 [00:00<00:03, 2897638.26it/s]Initializing MemoryTrace:  14%|█▍        | 1407493/10000000 [00:00<00:02, 3015933.31it/s]Initializing MemoryTrace:  17%|█▋        | 1732782/10000000 [00:00<00:02, 3096483.74it/s]Initializing MemoryTrace:  21%|██        | 2059806/10000000 [00:00<00:02, 3153276.82it/s]Initializing MemoryTrace:  24%|██▍       | 2387922/10000000 [00:00<00:02, 3193979.60it/s]Initializing MemoryTrace:  27%|██▋       | 2717188/10000000 [00:00<00:02, 3224817.26it/s]Initializing MemoryTrace:  30%|███       | 3047136/10000000 [00:01<00:02, 3247856.00it/s]Initializing MemoryTrace:  34%|███▍      | 3377293/10000000 [00:01<00:02, 3264284.16it/s]Initializing MemoryTrace:  37%|███▋      | 3707752/10000000 [00:01<00:01, 3276532.22it/s]